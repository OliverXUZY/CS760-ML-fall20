{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# res18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res18 = models.resnet18(pretrained = False)\n",
    "res18.conv1 = nn.Conv2d(1,64,kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "res18.fc = nn.Sequential(\n",
    "           nn.Linear(in_features=512, out_features=100, bias=True),\n",
    "           nn.ReLU(inplace=True),\n",
    "           nn.Dropout(p=0.5, inplace=False),\n",
    "           nn.Linear(in_features=100, out_features= 10, bias=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18.load_state_dict(torch.load('model/res18_epoch5.pt'))\n",
    "res18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.1367,  5.4201, -1.5383, -1.6602, -1.7947, -2.0198, -1.7400, -1.2598,\n",
       "         -1.9788, -2.0492]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18(torch.zeros([1, 1, 256, 256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res18 = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([256,256]),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      #transforms.CenterCrop(100),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "                             \n",
    "#image_datasets = {x:datasets.ImageFolder(os.path.join('CT', x), transform = data_transforms) for x in ['train','test']}\n",
    "image_datasets = {x:datasets.ImageFolder('CT/' + x, transform = data_transforms) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = image_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## transfer data(feature and y) to df\n",
    "# li = list(map(lambda x: res18(x[0].view(1,1,256,256))[0].data.numpy(), train))\n",
    "# df = pd.DataFrame(li)\n",
    "# df['y'] = list(map(lambda x: x[1],train))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in ['train','test']:\n",
    "    lst = list(map(lambda x: res18(x[0].view(1,1,256,256))[0].data.numpy(), image_datasets[i]))\n",
    "    df = pd.DataFrame(lst)\n",
    "    df['y'] = list(map(lambda x: x[1],image_datasets[i]))\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'].to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test'].to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "#num_classes = len(image_datasets['train'].classes)\n",
    "\n",
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class ConvNet3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        \n",
    "        #### YOUR CODE\n",
    "        self.conv1 = nn.Conv2d(1, 64,    kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, stride = 1, padding = 2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout2 = nn.Dropout2d(0.2)\n",
    "        self.batch2 = nn.BatchNorm2d(192)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.dropout3 = nn.Dropout2d(0.2)\n",
    "        self.batch3 = nn.BatchNorm2d(384)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dropout4 = nn.Dropout2d(0.2)\n",
    "        self.batch4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "        self.dropout5 = nn.Dropout2d(0.2)\n",
    "        self.batch5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        ## 256*256 adjuste by print size before linear 1\n",
    "        self.linear1 = nn.Linear(256 * 8 * 8, 4096)\n",
    "        self.lin_drop_1 = nn.Dropout(0.5)\n",
    "        self.lin_batch_1 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.linear2 = nn.Linear(4096, 512)\n",
    "        self.lin_drop_2 = nn.Dropout(0.5)\n",
    "        self.lin_batch_2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.linear3 = nn.Linear(512, 10)\n",
    "        #self.lin_drop_3 = nn.Dropout(0.5)\n",
    "        #self.lin_batch_3 = nn.BatchNorm1d(10)\n",
    "        \n",
    "        self.linear4 = nn.Linear(10, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #### YOUR CODE\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = torch.relu(out_1)\n",
    "        out_1 = self.pool1(out_1)\n",
    "        \n",
    "        out_2 = self.conv2(out_1)\n",
    "        out_2 = self.batch2(out_2)\n",
    "        out_2 = self.dropout2(out_2)\n",
    "        out_2 = torch.relu(out_2)\n",
    "        out_2 = self.pool2(out_2)\n",
    "        \n",
    "        out_3 = self.conv3(out_2)\n",
    "        out_3 = self.batch3(out_3)\n",
    "        out_3 = self.dropout3(out_3)\n",
    "        out_3 = torch.relu(out_3)\n",
    "        out_3 = self.pool3(out_3)\n",
    "        \n",
    "        out_4 = self.conv4(out_3)\n",
    "        out_4 = self.batch4(out_4)\n",
    "        out_4 = self.dropout4(out_4)\n",
    "        out_4 = torch.relu(out_4)\n",
    "        out_4 = self.pool4(out_4)\n",
    "        \n",
    "        out_5 = self.conv5(out_4)\n",
    "        out_5 = self.batch5(out_5)\n",
    "        out_5 = self.dropout5(out_5)\n",
    "        out_5 = self.pool5(out_5)\n",
    "        out_5 = torch.relu(out_5) \n",
    "        #print(out_5.size())\n",
    "        out_5 = out_5.view(-1,256 * 8 * 8)  ### -1 is adjusted batch size\n",
    "        #print(out_5.size())\n",
    "        \n",
    "        out_6 = self.linear1(out_5)\n",
    "        #print(out_6.size())\n",
    "        out_6 = self.lin_batch_1(out_6)\n",
    "        out_6 = torch.relu(out_6)\n",
    "        out_6 = self.lin_drop_1(out_6)\n",
    "        #print(out_6.size())\n",
    "        \n",
    "        out_7 = self.linear2(out_6)\n",
    "        out_7 = self.lin_batch_2(out_7)\n",
    "        out_7 = torch.relu(out_7)\n",
    "        out_7 = self.lin_drop_2(out_7)\n",
    "        #print(out_7.size())\n",
    "        \n",
    "        out_8 = self.linear3(out_7)\n",
    "        #out_8 = self.lin_batch_3(out_8)\n",
    "        out_8 = torch.relu(out_8)\n",
    "        #out_8 = self.lin_drop_3(out_8)\n",
    "        \n",
    "        out_9 = self.linear4(out_8)\n",
    "        \n",
    "        \n",
    "        logits = out_9\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "    def extract(self, x):\n",
    "\n",
    "        #### YOUR CODE\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = torch.relu(out_1)\n",
    "        out_1 = self.pool1(out_1)\n",
    "        \n",
    "        out_2 = self.conv2(out_1)\n",
    "        out_2 = self.batch2(out_2)\n",
    "        out_2 = self.dropout2(out_2)\n",
    "        out_2 = torch.relu(out_2)\n",
    "        out_2 = self.pool2(out_2)\n",
    "        \n",
    "        out_3 = self.conv3(out_2)\n",
    "        out_3 = self.batch3(out_3)\n",
    "        out_3 = self.dropout3(out_3)\n",
    "        out_3 = torch.relu(out_3)\n",
    "        out_3 = self.pool3(out_3)\n",
    "        \n",
    "        out_4 = self.conv4(out_3)\n",
    "        out_4 = self.batch4(out_4)\n",
    "        out_4 = self.dropout4(out_4)\n",
    "        out_4 = torch.relu(out_4)\n",
    "        out_4 = self.pool4(out_4)\n",
    "        \n",
    "        out_5 = self.conv5(out_4)\n",
    "        out_5 = self.batch5(out_5)\n",
    "        out_5 = self.dropout5(out_5)\n",
    "        out_5 = self.pool5(out_5)\n",
    "        out_5 = torch.relu(out_5) \n",
    "        #print(out_5.size())\n",
    "        out_5 = out_5.view(-1,256 * 8 * 8)  ### -1 is adjusted batch size  ## important so it's complicated to use method in nn.Sequential https://discuss.pytorch.org/t/how-to-extract-features-of-an-image-from-a-trained-model/119/3\n",
    "        #print(out_5.size())\n",
    "        \n",
    "        out_6 = self.linear1(out_5)\n",
    "        #print(out_6.size())\n",
    "        out_6 = self.lin_batch_1(out_6)\n",
    "        out_6 = torch.relu(out_6)\n",
    "        out_6 = self.lin_drop_1(out_6)\n",
    "        #print(out_6.size())\n",
    "        \n",
    "        out_7 = self.linear2(out_6)\n",
    "        out_7 = self.lin_batch_2(out_7)\n",
    "        out_7 = torch.relu(out_7)\n",
    "        out_7 = self.lin_drop_2(out_7)\n",
    "        #print(out_7.size())\n",
    "        \n",
    "        out_8 = self.linear3(out_7)\n",
    "        #out_8 = self.lin_batch_3(out_8)\n",
    "        #out_8 = torch.relu(out_8)\n",
    "        #out_8 = self.lin_drop_3(out_8)\n",
    "        \n",
    "        #out_9 = self.linear4(out_8)\n",
    "        \n",
    "        \n",
    "        #logits = out_9\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "        return out_8\n",
    "\n",
    "\n",
    "    \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model3 = ConvNet3(NUM_CLASSES)\n",
    "model3.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0624, -0.3482],\n",
       "         [ 0.0862,  0.0526]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.5710, 0.4290],\n",
       "         [0.5084, 0.4916]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(torch.zeros([2, 1, 256, 256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0537, -0.3711, -0.1043, -0.0624,  0.5342,  0.3770,  0.1038, -0.6191,\n",
       "          0.9731, -0.0918],\n",
       "        [-0.8433,  0.3586,  1.1264, -0.4315, -0.1242, -0.4194, -1.1390,  0.3371,\n",
       "         -0.2284,  0.2729]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.extract(torch.zeros([2, 1, 256, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet3(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout2d(p=0.2, inplace=False)\n",
       "  (batch2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout2d(p=0.2, inplace=False)\n",
       "  (batch3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(384, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout4): Dropout2d(p=0.2, inplace=False)\n",
       "  (batch4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout5): Dropout2d(p=0.2, inplace=False)\n",
       "  (batch5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "  (lin_drop_1): Dropout(p=0.5, inplace=False)\n",
       "  (lin_batch_1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (lin_drop_2): Dropout(p=0.5, inplace=False)\n",
       "  (lin_batch_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (linear4): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_state_dict(torch.load('model/model3_para_epoch30.pt', map_location=torch.device('cpu')))\n",
    "model3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.3009,  4.6892],\n",
       "         [-2.3009,  4.6892]], grad_fn=<AddmmBackward>),\n",
       " tensor([[9.2015e-04, 9.9908e-01],\n",
       "         [9.2015e-04, 9.9908e-01]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(torch.zeros([2, 1, 256, 256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.0935, -4.0854, -4.1818, -3.8889,  8.4424, -5.2277, -2.0680,  0.6597,\n",
       "         -4.2362, -3.4136],\n",
       "        [ 8.0935, -4.0854, -4.1818, -3.8889,  8.4424, -5.2277, -2.0680,  0.6597,\n",
       "         -4.2362, -3.4136]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.extract(torch.zeros([2, 1, 256, 256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([256,256]),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      #transforms.CenterCrop(100),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "                             \n",
    "#image_datasets = {x:datasets.ImageFolder(os.path.join('CT', x), transform = data_transforms) for x in ['train','test']}\n",
    "image_datasets = {x:datasets.ImageFolder('CT/' + x, transform = data_transforms) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = image_datasets['train']\n",
    "#train[1][0].view(1,1,256,256)[0]\n",
    "train[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transfer data(feature and y) to df\n",
    "li = list(map(lambda x: model3.extract(x[0].view(1,1,256,256))[0].data.numpy().reshape(-1), train))\n",
    "#df = pd.DataFrame(li)\n",
    "#df['y'] = list(map(lambda x: x[1],train))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in ['train','test']:\n",
    "    lst = list(map(lambda x: model3.extract(x[0].view(1,1,256,256))[0].data.numpy().reshape(-1), image_datasets[i]))\n",
    "    df = pd.DataFrame(lst)\n",
    "    df['y'] = list(map(lambda x: x[1],image_datasets[i]))\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.493340</td>\n",
       "      <td>1.979221</td>\n",
       "      <td>5.452313</td>\n",
       "      <td>2.376600</td>\n",
       "      <td>-2.218290</td>\n",
       "      <td>-0.297500</td>\n",
       "      <td>-2.463372</td>\n",
       "      <td>-2.882947</td>\n",
       "      <td>3.689015</td>\n",
       "      <td>-3.339031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.176325</td>\n",
       "      <td>-0.024176</td>\n",
       "      <td>1.475685</td>\n",
       "      <td>0.602422</td>\n",
       "      <td>2.101266</td>\n",
       "      <td>-0.889643</td>\n",
       "      <td>-0.977984</td>\n",
       "      <td>-1.051256</td>\n",
       "      <td>1.076921</td>\n",
       "      <td>-0.077088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.055301</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>2.598602</td>\n",
       "      <td>1.231147</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>-0.236204</td>\n",
       "      <td>-1.028547</td>\n",
       "      <td>-1.181248</td>\n",
       "      <td>1.844412</td>\n",
       "      <td>0.637139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.687569</td>\n",
       "      <td>2.378079</td>\n",
       "      <td>7.798402</td>\n",
       "      <td>4.224250</td>\n",
       "      <td>-2.453051</td>\n",
       "      <td>1.493909</td>\n",
       "      <td>-1.960688</td>\n",
       "      <td>-2.135546</td>\n",
       "      <td>5.440852</td>\n",
       "      <td>2.422818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.934954</td>\n",
       "      <td>3.237987</td>\n",
       "      <td>10.771603</td>\n",
       "      <td>6.296090</td>\n",
       "      <td>-3.865475</td>\n",
       "      <td>2.072758</td>\n",
       "      <td>-2.735177</td>\n",
       "      <td>-2.709528</td>\n",
       "      <td>7.688848</td>\n",
       "      <td>1.484118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>4.804821</td>\n",
       "      <td>-2.067938</td>\n",
       "      <td>-2.026330</td>\n",
       "      <td>-1.669337</td>\n",
       "      <td>5.694481</td>\n",
       "      <td>-3.133512</td>\n",
       "      <td>-1.433630</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>-2.073154</td>\n",
       "      <td>-2.740248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>3.176648</td>\n",
       "      <td>-1.120510</td>\n",
       "      <td>-0.873350</td>\n",
       "      <td>-0.638185</td>\n",
       "      <td>3.352316</td>\n",
       "      <td>-2.213702</td>\n",
       "      <td>-1.094906</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>-0.942316</td>\n",
       "      <td>-1.928452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>8.058622</td>\n",
       "      <td>-4.215203</td>\n",
       "      <td>-2.469227</td>\n",
       "      <td>-3.749281</td>\n",
       "      <td>6.763555</td>\n",
       "      <td>-5.871277</td>\n",
       "      <td>-2.440229</td>\n",
       "      <td>-0.194832</td>\n",
       "      <td>-4.219296</td>\n",
       "      <td>-2.010690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>7.688506</td>\n",
       "      <td>-3.652898</td>\n",
       "      <td>-3.489372</td>\n",
       "      <td>-3.320179</td>\n",
       "      <td>7.352696</td>\n",
       "      <td>-5.093736</td>\n",
       "      <td>-1.863724</td>\n",
       "      <td>0.569460</td>\n",
       "      <td>-3.843305</td>\n",
       "      <td>-3.414030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>8.389464</td>\n",
       "      <td>-4.077559</td>\n",
       "      <td>-3.955797</td>\n",
       "      <td>-3.687314</td>\n",
       "      <td>8.542190</td>\n",
       "      <td>-5.465669</td>\n",
       "      <td>-2.118549</td>\n",
       "      <td>0.753933</td>\n",
       "      <td>-4.286718</td>\n",
       "      <td>-3.890528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1          2         3         4         5         6  \\\n",
       "0   -5.493340  1.979221   5.452313  2.376600 -2.218290 -0.297500 -2.463372   \n",
       "1   -1.176325 -0.024176   1.475685  0.602422  2.101266 -0.889643 -0.977984   \n",
       "2   -2.055301  0.505205   2.598602  1.231147  0.399164 -0.236204 -1.028547   \n",
       "3   -3.687569  2.378079   7.798402  4.224250 -2.453051  1.493909 -1.960688   \n",
       "4   -4.934954  3.237987  10.771603  6.296090 -3.865475  2.072758 -2.735177   \n",
       "..        ...       ...        ...       ...       ...       ...       ...   \n",
       "641  4.804821 -2.067938  -2.026330 -1.669337  5.694481 -3.133512 -1.433630   \n",
       "642  3.176648 -1.120510  -0.873350 -0.638185  3.352316 -2.213702 -1.094906   \n",
       "643  8.058622 -4.215203  -2.469227 -3.749281  6.763555 -5.871277 -2.440229   \n",
       "644  7.688506 -3.652898  -3.489372 -3.320179  7.352696 -5.093736 -1.863724   \n",
       "645  8.389464 -4.077559  -3.955797 -3.687314  8.542190 -5.465669 -2.118549   \n",
       "\n",
       "            7         8         9  y  \n",
       "0   -2.882947  3.689015 -3.339031  0  \n",
       "1   -1.051256  1.076921 -0.077088  0  \n",
       "2   -1.181248  1.844412  0.637139  0  \n",
       "3   -2.135546  5.440852  2.422818  0  \n",
       "4   -2.709528  7.688848  1.484118  0  \n",
       "..        ...       ...       ... ..  \n",
       "641  0.369400 -2.073154 -2.740248  1  \n",
       "642  0.036718 -0.942316 -1.928452  1  \n",
       "643 -0.194832 -4.219296 -2.010690  1  \n",
       "644  0.569460 -3.843305 -3.414030  1  \n",
       "645  0.753933 -4.286718 -3.890528  1  \n",
       "\n",
       "[646 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'].to_csv('toymodel3_extracted_10_feature_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test'].to_csv('toymodel3_extracted_10_feature_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# didn't use raw data, can neglect below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([10,10]),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      #transforms.CenterCrop(100),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "                             \n",
    "#image_datasets = {x:datasets.ImageFolder(os.path.join('CT', x), transform = data_transforms) for x in ['train','test']}\n",
    "image_datasets = {x:datasets.ImageFolder('CT/' + x, transform = data_transforms) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets['train'][0][0][0].numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets['train'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in ['train','test']:\n",
    "    lst = list(map(lambda x: x[0][0].numpy().reshape(-1), image_datasets[i]))\n",
    "    df = pd.DataFrame(lst)\n",
    "    df['y'] = list(map(lambda x: x[1],image_datasets[i]))\n",
    "    data[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'].to_csv('train_raw.csv', index=False)\n",
    "data['test'].to_csv('test_raw.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train':             0         1         2         3         4         5         6  \\\n",
       " 0    0.447059  0.796078  0.854902  0.780392  0.886275  0.933333  0.941176   \n",
       " 1    0.721569  0.819608  0.784314  0.690196  0.819608  0.713726  0.596078   \n",
       " 2    0.666667  0.819608  0.784314  0.709804  0.866667  0.768627  0.576471   \n",
       " 3    0.933333  0.945098  0.682353  0.670588  0.929412  0.584314  0.349020   \n",
       " 4    0.737255  0.909804  0.917647  0.901961  0.945098  0.921569  0.827451   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 641  0.011765  0.129412  0.529412  0.509804  0.576471  0.756863  0.729412   \n",
       " 642  0.011765  0.145098  0.537255  0.584314  0.631373  0.733333  0.682353   \n",
       " 643  0.133333  0.231373  0.250980  0.333333  0.313726  0.317647  0.454902   \n",
       " 644  0.000000  0.003922  0.047059  0.121569  0.141176  0.141176  0.188235   \n",
       " 645  0.000000  0.000000  0.027451  0.078431  0.098039  0.094118  0.121569   \n",
       " \n",
       "             7         8         9  ...        91        92        93  \\\n",
       " 0    0.917647  0.858824  0.568627  ...  0.890196  0.823529  0.878431   \n",
       " 1    0.780392  0.882353  0.850980  ...  0.811765  0.537255  0.713726   \n",
       " 2    0.741176  0.858824  0.827451  ...  0.552941  0.356863  0.501961   \n",
       " 3    0.611765  0.945098  0.937255  ...  0.819608  0.674510  0.933333   \n",
       " 4    0.835294  0.898039  0.823529  ...  0.847059  0.560784  0.800000   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 641  0.521569  0.133333  0.003922  ...  0.109804  0.494118  0.737255   \n",
       " 642  0.490196  0.098039  0.003922  ...  0.113725  0.450980  0.713726   \n",
       " 643  0.411765  0.254902  0.156863  ...  0.239216  0.360784  0.384314   \n",
       " 644  0.113725  0.019608  0.000000  ...  0.149020  0.313726  0.352941   \n",
       " 645  0.070588  0.011765  0.000000  ...  0.105882  0.239216  0.337255   \n",
       " \n",
       "            94        95        96        97        98        99  y  \n",
       " 0    0.949020  0.917647  0.694118  0.717647  0.831373  0.917647  0  \n",
       " 1    0.886275  0.913725  0.815686  0.737255  0.854902  0.894118  0  \n",
       " 2    0.854902  0.898039  0.529412  0.282353  0.505882  0.882353  0  \n",
       " 3    0.984314  0.984314  0.984314  0.972549  0.988235  0.996078  0  \n",
       " 4    0.956863  0.949020  0.870588  0.811765  0.929412  0.956863  0  \n",
       " ..        ...       ...       ...       ...       ...       ... ..  \n",
       " 641  0.760784  0.764706  0.674510  0.388235  0.074510  0.058824  1  \n",
       " 642  0.733333  0.717647  0.607843  0.298039  0.062745  0.090196  1  \n",
       " 643  0.388235  0.396078  0.388235  0.368627  0.294118  0.031373  1  \n",
       " 644  0.290196  0.266667  0.349020  0.313726  0.141176  0.003922  1  \n",
       " 645  0.301961  0.294118  0.360784  0.286275  0.098039  0.003922  1  \n",
       " \n",
       " [646 rows x 101 columns],\n",
       " 'test':            0         1         2         3         4         5         6  \\\n",
       " 0   0.874510  0.862745  0.662745  0.466667  0.662745  0.411765  0.431373   \n",
       " 1   0.835294  0.886275  0.792157  0.537255  0.643137  0.498039  0.482353   \n",
       " 2   0.831373  0.674510  0.407843  0.533333  0.803922  0.823529  0.792157   \n",
       " 3   0.168627  0.172549  0.219608  0.376471  0.450980  0.482353  0.490196   \n",
       " 4   0.168627  0.172549  0.227451  0.396078  0.482353  0.513726  0.533333   \n",
       " ..       ...       ...       ...       ...       ...       ...       ...   \n",
       " 95  0.290196  0.639216  0.772549  0.854902  0.862745  0.854902  0.878431   \n",
       " 96  0.211765  0.509804  0.768627  0.831373  0.823529  0.811765  0.831373   \n",
       " 97  0.760784  0.768627  0.682353  0.721569  0.815686  0.835294  0.619608   \n",
       " 98  0.898039  0.894118  0.890196  0.866667  0.890196  0.886275  0.839216   \n",
       " 99  0.172549  0.180392  0.305882  0.635294  0.729412  0.705882  0.678431   \n",
       " \n",
       "            7         8         9  ...        91        92        93        94  \\\n",
       " 0   0.713726  0.866667  0.831373  ...  0.756863  0.694118  0.831373  0.886275   \n",
       " 1   0.717647  0.854902  0.815686  ...  0.850980  0.807843  0.850980  0.890196   \n",
       " 2   0.686275  0.741176  0.819608  ...  0.819608  0.788235  0.850980  0.866667   \n",
       " 3   0.298039  0.176471  0.164706  ...  0.392157  0.509804  0.560784  0.517647   \n",
       " 4   0.329412  0.180392  0.164706  ...  0.423529  0.576471  0.623529  0.568627   \n",
       " ..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       " 95  0.807843  0.552941  0.282353  ...  0.776471  0.792157  0.843137  0.890196   \n",
       " 96  0.772549  0.447059  0.196078  ...  0.572549  0.784314  0.854902  0.839216   \n",
       " 97  0.458824  0.701961  0.788235  ...  0.772549  0.572549  0.756863  0.866667   \n",
       " 98  0.874510  0.894118  0.882353  ...  0.909804  0.847059  0.850980  0.909804   \n",
       " 99  0.419608  0.180392  0.141176  ...  0.184314  0.360784  0.643137  0.768627   \n",
       " \n",
       "           95        96        97        98        99  y  \n",
       " 0   0.858824  0.705882  0.650980  0.823529  0.890196  0  \n",
       " 1   0.866667  0.756863  0.729412  0.850980  0.890196  0  \n",
       " 2   0.870588  0.698039  0.431373  0.564706  0.831373  0  \n",
       " 3   0.482353  0.482353  0.396078  0.333333  0.321569  0  \n",
       " 4   0.533333  0.529412  0.431373  0.345098  0.321569  0  \n",
       " ..       ...       ...       ...       ...       ... ..  \n",
       " 95  0.890196  0.815686  0.756863  0.784314  0.447059  1  \n",
       " 96  0.839216  0.843137  0.780392  0.588235  0.219608  1  \n",
       " 97  0.862745  0.815686  0.776471  0.835294  0.772549  1  \n",
       " 98  0.905882  0.917647  0.901961  0.905882  0.764706  1  \n",
       " 99  0.823529  0.788235  0.580392  0.235294  0.043137  1  \n",
       " \n",
       " [100 rows x 101 columns]}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(map(lambda x: x[0][0].numpy(), image_datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
